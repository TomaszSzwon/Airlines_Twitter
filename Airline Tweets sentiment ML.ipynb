{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2d1231f0-da31-45a7-a561-7e6c1bf64ecc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d1231f0-da31-45a7-a561-7e6c1bf64ecc",
        "outputId": "fb1434b5-b623-49dc-e615-05f3da3f1c5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Raport klasyfikacji:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.81      0.82      1860\n",
            "           1       0.77      0.86      0.82      1871\n",
            "           2       0.81      0.49      0.61       437\n",
            "\n",
            "    accuracy                           0.80      4168\n",
            "   macro avg       0.80      0.72      0.75      4168\n",
            "weighted avg       0.80      0.80      0.80      4168\n",
            "\n",
            "\n",
            "🎯 Dokładność modelu: 0.8018234165067178\n",
            "\n",
            "🔹 Najbardziej wpływowe słowa dla klasy 'negative':\n",
            "['worse', 'delay', 'customers', 'hour', 'cancelled', 'luggage', 'hold', 'delayed', 'hours', 'worst']\n",
            "\n",
            "🔹 Najbardziej wpływowe słowa dla klasy 'neutral':\n",
            "['saw', 'number', 'impression', 'winners', 'hungupnohelp', 'journal', 'guarantee', 'possible', 'question', 'chance']\n",
            "\n",
            "🔹 Najbardziej wpływowe słowa dla klasy 'positive':\n",
            "['rock', 'excellent', 'appreciate', 'best', 'amazing', 'love', 'awesome', 'great', 'thank', 'thanks']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Wczytanie danych\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/TomaszSzwon/Airlines_Twitter/refs/heads/main/Tweets_Kaggle_Clean.csv\")\n",
        "\n",
        "# Pobranie listy stopwords\n",
        "nltk.download('stopwords') #biblioteka\n",
        "nltk.download('punkt_tab') #biblioteka puntorów\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Lista nazw linii lotniczych i nieistotnych zwrotów\n",
        "unnecessary_words = [\"united\", \"american\", \"delta\", \"southwest\", \"jetblue\", \"virginamerica\", \"usairways\",\n",
        "                      \"flight\", \"flights\", \"airline\", \"plane\", \"hi\", \"hello\", \"australia\", \"hawaii\", \"mexico\", \"atlanta\", \"march\", \"462\"]\n",
        "\n",
        "#Aktualizacja 'stopwords'\n",
        "stop_words.update(unnecessary_words)  # Dodajemy zbędne słowa do listy stopwords\n",
        "\n",
        "# Funkcja do czyszczenia tekstu\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Małe litery\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)  # Usunięcie linków\n",
        "    text = re.sub(r\"@\\S+|#\\S+\", \"\", text)  # Usunięcie mentionów i hashtagów\n",
        "    tokens = word_tokenize(text)  # Tokenizacja\n",
        "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Zastosowanie funkcji do danych\n",
        "df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
        "\n",
        "# Filtrujemy neutralne tweety\n",
        "neutral_tweets = df[df[\"airline_sentiment\"] == \"neutral\"]\n",
        "\n",
        "# Zduplikowanie neutralnych tweetów\n",
        "df_oversampled = pd.concat([df, neutral_tweets, neutral_tweets], ignore_index=True)\n",
        "\n",
        "# TF-IDF-przekształca tekst w macierz liczbową na podstawie miary TF-IDF (Term Frequency-Inverse Document Frequency).\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=5000)\n",
        "X = vectorizer.fit_transform(df_oversampled[\"clean_text\"])\n",
        "\n",
        "y = df_oversampled[\"airline_sentiment\"].map({\"negative\": 0, \"neutral\": 1, \"positive\": 2})  # Konwersja etykiet sentymentu na liczby\n",
        "\n",
        "# Podział danych na zbiór treningowy i testowy\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model regresji logistycznej\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Raport\n",
        "print(\"\\n📊 Raport klasyfikacji:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\n🎯 Dokładność modelu:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Analiza wpływowych słów\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "class_labels = [\"negative\", \"neutral\", \"positive\"]\n",
        "\n",
        "for i, label in enumerate(class_labels):\n",
        "    top_words = np.argsort(model.coef_[i])[-10:]\n",
        "    print(f\"\\n🔹 Najbardziej wpływowe słowa dla klasy '{label}':\")\n",
        "    print([feature_names[j] for j in top_words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6abebee0-25ed-47d2-9486-63a41f01d155",
      "metadata": {
        "id": "6abebee0-25ed-47d2-9486-63a41f01d155",
        "outputId": "1bb5016d-c845-4acb-df59-f66a889fd3f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet: Once again @airline_name delayed my flight! This is the third time in a row, it’s clear they can't manage their schedule. It's getting really frustrating! 😤\n",
            "🔍 Przewidziany sentyment: negative\n",
            "--------------------------------------------------\n",
            "Tweet: I recently flew with @airline_name and I have to say, the service was amazing! Comfortable seats, great food, and a very friendly crew. I'll definitely fly with them again! ✈️😊\n",
            "🔍 Przewidziany sentyment: positive\n",
            "--------------------------------------------------\n",
            "Tweet: Flew today with @airline_name. The flight went by without any major issues, but nothing really stood out. Just an ordinary trip.\n",
            "🔍 Przewidziany sentyment: negative\n",
            "--------------------------------------------------\n",
            "Tweet: I always enjoy flying with @airline_name, but today I feel like a VIP – all the pilots smiling and the flight attendants are almost too friendly! 😂✈️\n",
            "🔍 Przewidziany sentyment: positive\n",
            "--------------------------------------------------\n",
            "Tweet: Just landed in Paris. No delays, everything went smoothly.\n",
            "🔍 Przewidziany sentyment: negative\n",
            "--------------------------------------------------\n",
            "Tweet: Waiting for my flight to board. The gate area is a bit crowded, but it’s manageable.\n",
            "🔍 Przewidziany sentyment: negative\n",
            "--------------------------------------------------\n",
            "Tweet: Saw an interesting article about air travel today. Looks like there are a lot of new safety regulations.\n",
            "🔍 Przewidziany sentyment: neutral\n",
            "--------------------------------------------------\n",
            "Tweet: Got my boarding pass. Still have some time before the flight, so just relaxing.\n",
            "🔍 Przewidziany sentyment: neutral\n",
            "--------------------------------------------------\n",
            "Tweet: The airport was pretty busy today, but it’s always like that around this time.\n",
            "🔍 Przewidziany sentyment: negative\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "tweets = [\n",
        "    \"Once again @airline_name delayed my flight! This is the third time in a row, it’s clear they can't manage their schedule. It's getting really frustrating! 😤\",\n",
        "    \"I recently flew with @airline_name and I have to say, the service was amazing! Comfortable seats, great food, and a very friendly crew. I'll definitely fly with them again! ✈️😊\",\n",
        "    \"Flew today with @airline_name. The flight went by without any major issues, but nothing really stood out. Just an ordinary trip.\",\n",
        "    \"I always enjoy flying with @airline_name, but today I feel like a VIP – all the pilots smiling and the flight attendants are almost too friendly! 😂✈️\",\n",
        "    \"Just landed in Paris. No delays, everything went smoothly.\",\n",
        "    \"Waiting for my flight to board. The gate area is a bit crowded, but it’s manageable.\",\n",
        "    \"Saw an interesting article about air travel today. Looks like there are a lot of new safety regulations.\",\n",
        "    \"Got my boarding pass. Still have some time before the flight, so just relaxing.\",\n",
        "    \"The airport was pretty busy today, but it’s always like that around this time.\"\n",
        "]\n",
        "\n",
        "def analyze_tweets(tweets):\n",
        "    sentiment_labels = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
        "\n",
        "    for tweet in tweets:\n",
        "        clean_tweet = clean_text(tweet)  # Oczyszczenie\n",
        "        vectorized_tweet = vectorizer.transform([clean_tweet])  # Przekształcenie TF-IDF\n",
        "        prediction = model.predict(vectorized_tweet)[0]  # Przewidywanie sentymentu\n",
        "        print(f\"Tweet: {tweet}\")\n",
        "        print(\"🔍 Przewidziany sentyment:\", sentiment_labels[prediction])\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "analyze_tweets(tweets)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}